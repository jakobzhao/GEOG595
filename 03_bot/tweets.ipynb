{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "comic-detroit",
      "metadata": {
        "id": "comic-detroit"
      },
      "outputs": [],
      "source": [
        "# created on Dec 24, 2020\n",
        "# modified on April 14, 2021\n",
        "# modified on Jan 2, 2021\n",
        "# @author:          Bo Zhao\n",
        "# @email:           zhaobo@uw.edu\n",
        "# @website:         https://hgis.uw.edu\n",
        "# @organization:    Department of Geography, University of Washington, Seattle\n",
        "# @description:     Search historical tweets using locational information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "2hob_1iXn14t",
      "metadata": {
        "id": "2hob_1iXn14t"
      },
      "outputs": [],
      "source": [
        "import tweepy\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "WHeExfSloBhI",
      "metadata": {
        "id": "WHeExfSloBhI"
      },
      "outputs": [],
      "source": [
        "# the file path where to store the output csv on google drive\n",
        "output_file = '/gdrive/My Drive/tweets.csv'\n",
        "\n",
        "# Apply for your own Twitter API keys at https://developer.twitter.com/en/apply-for-access\n",
        "consumer_key = \"your_consumer_key\"\n",
        "consumer_secret = \"your_consumer_secret\"\n",
        "access_token = \"your_access_token\"\n",
        "access_token_secret = \"your_access_token_secret\"\n",
        "\n",
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "api = tweepy.API(auth, wait_on_rate_limit=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "passing-pulse",
      "metadata": {
        "id": "passing-pulse"
      },
      "outputs": [],
      "source": [
        "# Define the search term and the date_since date as variables\n",
        "search_words = \"#BLM\"\n",
        "location = \"47.6138893,-122.3107869,100mi\"\n",
        "date_since = \"2020-10-16\"\n",
        "# read the Twitter API document to look for other ways to customize your queries.\n",
        "# refer to https://developer.twitter.com/en/docs/twitter-api/v1/rules-and-filtering/search-operators\n",
        "# for example: you can ignore all the retweets by #wildfires -filter:retweets\n",
        "# Geolocalization: the search operator “near” isn’t available in the API, but there is a more precise way to restrict\n",
        "# your query by a given location using the geocode parameter specified with the template “latitude,longitude,radius”,\n",
        "# for example, “47.6138893,-122.3107869,10mi” (capitol hill at Seattle). When conducting geo searches, the search API will first attempt to find Tweets、\n",
        "# which have lat/long within the queried geocode, and in case of not having success, it will attempt to find Tweets created\n",
        "# by users whose profile location can be reverse geocoded into a lat/long within the queried geocode, meaning that is possible\n",
        "# to receive Tweets which do not include lat/long information.\n",
        "\n",
        "\n",
        "# Collect tweets\n",
        "# tweets = tweepy.Cursor(api.search, q=search_words, lang=\"en\", since=date_since).items(100)\n",
        "tweets = tweepy.Cursor(api.search, q=search_words, geocode=location, lang=\"en\", since=date_since).items(1000)\n",
        "\n",
        "# create an array to store the result\n",
        "result = []\n",
        "\n",
        "# Iterate and print tweets\n",
        "for tweet in tweets:\n",
        "    row = {\n",
        "        'username': tweet.author.name,\n",
        "        'userid': tweet.author.id,\n",
        "        'profile_location': tweet.author.location,\n",
        "        'created_at': str(tweet.created_at),,\n",
        "        'text': tweet.text,\n",
        "        'retweet_count': tweet.retweet_count,\n",
        "        'source': tweet.source,\n",
        "        'coordinates': tweet.coordinates\n",
        "    }\n",
        "    result.append(row)\n",
        "    print(row)\n",
        "\n",
        "# Store the results as a pandas dataframe\n",
        "df = pd.DataFrame(result)\n",
        "\n",
        "# notify the completion of the crawling in the console.\n",
        "print(\"the crawling task is finished.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Zm98obJ2onCV",
      "metadata": {
        "id": "Zm98obJ2onCV"
      },
      "outputs": [],
      "source": [
        "# Create data on to Google Drive\n",
        "from google.colab import drive\n",
        "# Mount your Drive to the Colab VM.\n",
        "drive.mount('/gdrive')\n",
        "  \n",
        "df.to_csv(output_file, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GMywhiuFoobU",
      "metadata": {
        "id": "GMywhiuFoobU"
      },
      "outputs": [],
      "source": [
        "# download the csv to your local computer\n",
        "from google.colab import files\n",
        "files.download(output_file)\n",
        "print(\"the csv has been downloaded to your local computer. The program has been completed successfully.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "tweets.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
